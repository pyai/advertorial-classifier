{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jupyter/gitlab/advertorial-classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorial import dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "#import wandb\n",
    "import numpy as np\n",
    "#import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # advertorial_dataset = dataset.train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted.csv')\n",
    "# # train, validation, test = advertorial_dataset['train'], advertorial_dataset['validation'], advertorial_dataset['test'] \n",
    "# # id2label = {0: \"no\", 1: \"yes\"}\n",
    "# # label2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "# # pretrain_model =\"hfl/chinese-bert-wwm-ext\"\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained(\n",
    "# #     pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "\n",
    "\n",
    "# advertorial_dataset = dataset.train_valid_test_from_file(csv_file_path='./data/milelens_advertorial_dataset_formatted.csv', train_ratio=0.8, validation_ratio=0.2 )#'./data/unseen_2023-05-30.csv', train_ratio=1)\n",
    "# train = advertorial_dataset['train']\n",
    "# valid = advertorial_dataset['validation']\n",
    "\n",
    "# id2label = {0: \"no\", 1: \"yes\"}\n",
    "# label2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "# pretrain_model =\"hfl/chinese-bert-wwm-ext\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_valid_test_from_file() got an unexpected keyword argument 'csv_file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mtrain_valid_test_from_file(csv_file_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/train_set_2023-07-20.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, train_ratio\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m )\n\u001b[1;32m      2\u001b[0m valid_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtrain_valid_test_from_file(csv_file_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data/valid_set_2023-07-20.csv\u001b[39m\u001b[39m'\u001b[39m, train_ratio\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m )\n\u001b[1;32m      3\u001b[0m \u001b[39m#'./data/unseen_2023-05-30.csv', train_ratio=1)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_valid_test_from_file() got an unexpected keyword argument 'csv_file_path'"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.train_valid_test_from_file(csv_file_path='./data/train_set_2023-07-20.csv', train_ratio=1 )\n",
    "valid_dataset = dataset.train_valid_test_from_file(csv_file_path='./data/valid_set_2023-07-20.csv', train_ratio=1 )\n",
    "#'./data/unseen_2023-05-30.csv', train_ratio=1)\n",
    "train = train_dataset['train']\n",
    "valid = valid_dataset['train']\n",
    "id2label = {0: \"no\", 1: \"yes\"}\n",
    "label2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "pretrain_model =\"hfl/chinese-bert-wwm-ext\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorial.inference import AdvertorialModel\n",
    "adv = AdvertorialModel(model_path='./prebuilt_model/230720_chinese_bert_wwm_ext', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def perf_report(model, dataset, name='train'):\n",
    "    from tqdm import tqdm\n",
    "    N = len(dataset)\n",
    "    step = 20\n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    predictions = []\n",
    "    for s in tqdm(range(0, N, step)):\n",
    "        s, e = s, s+step\n",
    "        prediction, probs = model(dataset[s:e]['text'])\n",
    "        \n",
    "        hits += np.sum(dataset[s:e]['label'] == prediction)\n",
    "        miss += np.sum(dataset[s:e]['label'] != prediction)\n",
    "        zeros += np.sum(dataset[s:e]['label'] == np.array(0))\n",
    "        ones += np.sum(dataset[s:e]['label'] == np.array(1))\n",
    "        fp += np.sum((dataset[s:e]['label'] != prediction) & (dataset[s:e]['label'] == np.array(0)))\n",
    "        fn += np.sum((dataset[s:e]['label'] != prediction) & (dataset[s:e]['label'] == np.array(1)))\n",
    "        tp += np.sum((dataset[s:e]['label'] == prediction) & (dataset[s:e]['label'] == np.array(1)))\n",
    "        tn += np.sum((dataset[s:e]['label'] == prediction) & (dataset[s:e]['label'] == np.array(0)))\n",
    "        predictions.append(prediction) \n",
    "\n",
    "    accuracy = hits/N\n",
    "    print(f'accuracy:{accuracy:.2f}, positive samples:{ones}, negative samples:{zeros}')  \n",
    "    performance_df = pd.DataFrame({'dataset':[name], \n",
    "                                   'records':[N], \n",
    "                                   'positive samples':[ones], \n",
    "                                   'negative samples':[zeros], \n",
    "                                   'hit':[hits],\n",
    "                                   'miss':[miss],\n",
    "                                   'accuracy':[accuracy], \n",
    "                                   'miss rate':[1-accuracy], \n",
    "                                   'false pos rate':[fp/(tn+fp)], \n",
    "                                   'false neg rate':[fn/(tp+fn)],\n",
    "                                   'true pos rate (sensitivity)':[tp/(tp+fn)],\n",
    "                                   'true neg rate (specificity)':[tn/(tn+fp)],\n",
    "                                   'precision':[tp/(tp+fp)]})\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    error_ids = predictions != dataset['label']\n",
    "    error_df = pd.DataFrame({'text':np.array(dataset['text'])[error_ids], 'label':np.array(dataset['label'])[error_ids], 'prediction':predictions[error_ids]})\n",
    "    return error_df, performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_perf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_perf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_perf' is not defined"
     ]
    }
   ],
   "source": [
    "train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2249/2249 [13:13<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.97, positive samples:16511, negative samples:28461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [03:17<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.82, positive samples:4125, negative samples:7119\n"
     ]
    }
   ],
   "source": [
    "train_error, train_perf = perf_report(adv, train, 'train')\n",
    "validation_error, validation_perf = perf_report(adv, valid, 'validation')\n",
    "#test_error, test_perf = perf_report(adv, test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>train</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>records</th>\n",
       "      <td>44972</td>\n",
       "      <td>11244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive samples</th>\n",
       "      <td>16511</td>\n",
       "      <td>4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative samples</th>\n",
       "      <td>28461</td>\n",
       "      <td>7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit</th>\n",
       "      <td>43473</td>\n",
       "      <td>9187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss</th>\n",
       "      <td>1499</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.966668</td>\n",
       "      <td>0.817058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss rate</th>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.182942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false pos rate</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.144683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false neg rate</th>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.24897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true pos rate (sensitivity)</th>\n",
       "      <td>0.95821</td>\n",
       "      <td>0.75103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true neg rate (specificity)</th>\n",
       "      <td>0.971575</td>\n",
       "      <td>0.855317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.951353</td>\n",
       "      <td>0.750484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0           1\n",
       "dataset                         train  validation\n",
       "records                         44972       11244\n",
       "positive samples                16511        4125\n",
       "negative samples                28461        7119\n",
       "hit                             43473        9187\n",
       "miss                             1499        2057\n",
       "accuracy                     0.966668    0.817058\n",
       "miss rate                    0.033332    0.182942\n",
       "false pos rate               0.028425    0.144683\n",
       "false neg rate                0.04179     0.24897\n",
       "true pos rate (sensitivity)   0.95821     0.75103\n",
       "true neg rate (specificity)  0.971575    0.855317\n",
       "precision                    0.951353    0.750484"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat([train_perf, validation_perf, test_perf]).reset_index(drop=True)#.to_csv('performance.csv', index=False)\n",
    "pd.concat([train_perf, validation_perf]).reset_index(drop=True).T#.to_csv('performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/業配文期末考題目.xlsx', sheet_name='Sheet1')\n",
    "#df = df.rename(columns={'貼文內容':'text', '正確答案':'label'})[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "join = train_error.merge(df, left_on='text', right_on='貼文內容', how='left')\n",
    "join[['貼文內容', '正確答案', 'label', 'prediction', '貼文連結']].to_csv('業配文期末考題目_錯誤部分.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advertorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
