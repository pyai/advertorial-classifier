{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a8bb1c-b6ee-452c-aba5-2ae1aa964e5f",
   "metadata": {},
   "source": [
    "# Clean data for Vertex AI training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6010519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/bonzo_yang/gitlab/advertorial-classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032f7388-9cab-4339-b87c-8dc1bd766ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorial import dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import wandb\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6db3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "advertorial_dataset = dataset.train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted.csv')\n",
    "train, validation, test = advertorial_dataset['train'], advertorial_dataset['validation'], advertorial_dataset['test'] \n",
    "id2label = {0: \"no\", 1: \"yes\"}\n",
    "label2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "pretrain_model =\"hfl/chinese-bert-wwm-ext\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc28081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2876efb0fe847c1b289943c633f2280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4514833865c44cd8bfc93377d27b8777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbf95b86f6f4bc5be83cc9512073680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbonzo-yang-cloudmile\u001b[0m (\u001b[33mcm-ml-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/bonzo_yang/gitlab/advertorial-classifier/wandb/run-20230520_003129-9vje78bt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cm-ml-team/milelens-ml-advertorial/runs/9vje78bt' target=\"_blank\">breezy-wind-28</a></strong> to <a href='https://wandb.ai/cm-ml-team/milelens-ml-advertorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cm-ml-team/milelens-ml-advertorial' target=\"_blank\">https://wandb.ai/cm-ml-team/milelens-ml-advertorial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cm-ml-team/milelens-ml-advertorial/runs/9vje78bt' target=\"_blank\">https://wandb.ai/cm-ml-team/milelens-ml-advertorial/runs/9vje78bt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "\n",
    "\n",
    "tokenized_advertorial = advertorial_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Data collator that will dynamically pad the inputs received\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "use_wandb = True\n",
    "report_args = []\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"milelens-ml-advertorial\")\n",
    "\n",
    "    report_args.append(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1d6764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/bonzo_yang/venv/kol_exp/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3680\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2300\n",
      "  Number of trainable parameters = 102269186\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1081' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1081/2300 09:23 < 10:36, 1.92 it/s, Epoch 4.70/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.402016</td>\n",
       "      <td>0.845652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.425779</td>\n",
       "      <td>0.808696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>0.852174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.525738</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-230\n",
      "Configuration saved in prebuilt_model/log/checkpoint-230/config.json\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-230\n",
      "Configuration saved in prebuilt_model/log/checkpoint-230/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-230/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-230/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-230/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-460\n",
      "Configuration saved in prebuilt_model/log/checkpoint-460/config.json\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-460\n",
      "Configuration saved in prebuilt_model/log/checkpoint-460/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-460/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-690\n",
      "Configuration saved in prebuilt_model/log/checkpoint-690/config.json\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-690\n",
      "Configuration saved in prebuilt_model/log/checkpoint-690/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-690/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-690/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-690/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-920\n",
      "Configuration saved in prebuilt_model/log/checkpoint-920/config.json\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-920\n",
      "Configuration saved in prebuilt_model/log/checkpoint-920/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-920/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-920/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-920/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-1150\n",
      "Configuration saved in prebuilt_model/log/checkpoint-1150/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-1150/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-1150/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-1150/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-1380\n",
      "Configuration saved in prebuilt_model/log/checkpoint-1380/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-1380/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-1380/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-1380/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-1610\n",
      "Configuration saved in prebuilt_model/log/checkpoint-1610/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-1610/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-1610/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-1610/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-1840\n",
      "Configuration saved in prebuilt_model/log/checkpoint-1840/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-1840/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-1840/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-1840/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-2070\n",
      "Configuration saved in prebuilt_model/log/checkpoint-2070/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-2070/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-2070/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-2070/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 460\n",
      "Saving model checkpoint to prebuilt_model/log/checkpoint-2300\n",
      "Configuration saved in prebuilt_model/log/checkpoint-2300/config.json\n",
      "Model weights saved in prebuilt_model/log/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in prebuilt_model/log/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in prebuilt_model/log/checkpoint-2300/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2300, training_loss=0.1599029072471287, metrics={'train_runtime': 1217.0343, 'train_samples_per_second': 30.237, 'train_steps_per_second': 1.89, 'total_flos': 9588613746027840.0, 'train_loss': 0.1599029072471287, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    #logging_steps=10000,\n",
    "    #save_steps=10000,\n",
    "    output_dir=\"prebuilt_model/log\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    #evaluation_strategy=\"steps\"\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    #fp16=True,\n",
    "    #load_best_model_at_end=True,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_advertorial[\"train\"],\n",
    "    eval_dataset=tokenized_advertorial[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9027f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bonzo_yang/gitlab/advertorial-classifier\n"
     ]
    }
   ],
   "source": [
    "from advertorial.inference import AdvertorialModel\n",
    "adv = AdvertorialModel(use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a41a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba32e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6935d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "a\n",
    "torch.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba4fe07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./tests/test.csv')\n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "acf51042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.softmax(adv(texts, return_logit=True).logits, dim=1) > 0.5).int().argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da169542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541c9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['三年沒來日本 第一站先衝迪士尼🇯🇵', '拉麵王子推薦新宿拉麵看了嗎？吃個日本泡麵解拉麵癮']\n",
    "# 0, 1\n",
    "prediction, probs = adv(text, return_logit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b50a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(prediction.tolist() == np.array([0, 1])).tolist()#.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bce82aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_ =  (F.softmax(outputs.logits, dim=1) > 0.6).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da99f597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_.argmax(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "472b0451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = adv(text)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef9ff9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397],\n",
       "        [ 4.3773, -4.4424],\n",
       "        [-3.7513,  3.7397]], device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "text = ['三年沒來日本 第一站先衝迪士尼🇯🇵', '拉麵王子推薦新宿拉麵看了嗎？吃個日本泡麵解拉麵癮']*17\n",
    "outputs = adv(text, return_logit=True)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf2a515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a31e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def perf_report(model, dataset, name='train'):\n",
    "    from tqdm import tqdm\n",
    "    N = len(dataset)\n",
    "    step = 20\n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    hits = 0\n",
    "    miss = 0\n",
    "    predictions = []\n",
    "    for s in tqdm(range(0, N, step)):\n",
    "        s, e = s, s+step\n",
    "        prediction, probs = model(dataset[s:e]['text'])\n",
    "        \n",
    "        hits += np.sum(dataset[s:e]['label'] == prediction)\n",
    "        miss += np.sum(dataset[s:e]['label'] != prediction)\n",
    "        zeros += np.sum(dataset[s:e]['label'] == np.array(0))\n",
    "        ones += np.sum(dataset[s:e]['label'] == np.array(1))\n",
    "        predictions.append(prediction) \n",
    "\n",
    "    accuracy = hits/N\n",
    "    print(f'accuracy:{accuracy:.2f}, positive samples:{ones}, negative samples:{zeros}')  \n",
    "    performance_df = pd.DataFrame({'dataset':[name], \n",
    "                                   'records':[N], \n",
    "                                   'positive samples':[ones], \n",
    "                                   'negative samples':[zeros], \n",
    "                                   'hit':[hits],\n",
    "                                   'miss':[miss],\n",
    "                                   'accuracy':[accuracy], 'miss rate':[1-accuracy]})\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    error_ids = predictions != dataset['label']\n",
    "    error_df = pd.DataFrame({'text':np.array(dataset['text'])[error_ids], 'label':np.array(dataset['label'])[error_ids], 'prediction':predictions[error_ids]})\n",
    "    return error_df, performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1006436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:36<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.97, positive samples:1733, negative samples:1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.98, positive samples:214, negative samples:246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:04<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.96, positive samples:203, negative samples:257\n"
     ]
    }
   ],
   "source": [
    "train_error, train_perf = perf_report(adv, train, 'train')\n",
    "validation_error, validation_perf = perf_report(adv, validation, 'validation')\n",
    "test_error, test_perf = perf_report(adv, test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a17118e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>records</th>\n",
       "      <th>positive samples</th>\n",
       "      <th>negative samples</th>\n",
       "      <th>hit</th>\n",
       "      <th>miss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>miss rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3680</td>\n",
       "      <td>1733</td>\n",
       "      <td>1947</td>\n",
       "      <td>3570</td>\n",
       "      <td>110</td>\n",
       "      <td>0.970109</td>\n",
       "      <td>0.029891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation</td>\n",
       "      <td>460</td>\n",
       "      <td>214</td>\n",
       "      <td>246</td>\n",
       "      <td>451</td>\n",
       "      <td>9</td>\n",
       "      <td>0.980435</td>\n",
       "      <td>0.019565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>460</td>\n",
       "      <td>203</td>\n",
       "      <td>257</td>\n",
       "      <td>442</td>\n",
       "      <td>18</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.039130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset  records  positive samples  negative samples   hit  miss  \\\n",
       "0       train     3680              1733              1947  3570   110   \n",
       "0  validation      460               214               246   451     9   \n",
       "0        test      460               203               257   442    18   \n",
       "\n",
       "   accuracy  miss rate  \n",
       "0  0.970109   0.029891  \n",
       "0  0.980435   0.019565  \n",
       "0  0.960870   0.039130  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_perf, validation_perf, test_perf]).reset_index(drop=True)#.to_csv('performance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ced670f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error.to_csv('train_error.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ebb3f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error.to_csv('test_error.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f90197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 45)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_error.label==1), np.sum(train_error.label==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f833934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(validation_error.label==1), np.sum(validation_error.label==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "928f7fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_error.label==1), np.sum(test_error.label==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac8ba0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(validation)\n",
    "step = 10\n",
    "ones = 0\n",
    "zeros = 0\n",
    "hits = 0\n",
    "for s in tqdm(range(0, N, step)):\n",
    "    s, e = s, s+step\n",
    "    prediction, probs = adv(validation[s:e]['text'])\n",
    "    \n",
    "    hits += np.sum(validation[s:e]['label'] == prediction)\n",
    "    zeros = np.sum(validation[s:e]['label'] == 0)\n",
    "    ones = np.sum(validation[s:e]['label']==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da25caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['瑋瑋：我們要去香港啦！大約下午一點抵達，這次偷偷租了一個地方跟三年沒見的大家見面，沒有告訴哲哲🤪🤪🤪 歡迎有空的香港觀眾來玩！  地點：荃灣德士古道120號安泰國際中心20樓2003室（THE HOUSE攝影棚） 入場時間：2023/01/18 晚上六點進場 活動開始：18：30-19：30 費用：免費！你們人來就好💞💞💞 來看看我們超臨時的聚會，會有多少香港觀眾來呢？',\n",
       " '#drgracieofficial  謝謝你們今天來看直播。 祝大家有美好的每一天！  過好當下、讓自己快樂，不影響別人、維持健康； 這樣就好。  晚安😴  G. Hsu  一直以為文章發出去了 結果沒有😭',\n",
       " '今天要住的飯店是… 半年前才訂得到的Disney hotel 🏰  相隔三年來東京覺得超級陌生 完全沒坐功課…. 電車要怎麼搭都完全忘了 也忘記日本有什麼好吃的食物\\U0001f979 大家有推薦的話留言告訴我一下 很需要被推薦….',\n",
       " '新年快樂！2023一起努力🥰',\n",
       " 'Red Bull飛行日的影片上線囉～ 真的很好玩  團隊的大家辛苦了～  好可惜我覺得我們的飛行器還有很多可以加強的地方 本來是想說用把飛行員丟出去這個概念來呈現飛行這個主題 但效果好像不太理想ˊ<__ˋ 我們再接再厲 再來挑戰更有趣的東西  下次見ˊVˋ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd20e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "00d1bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted.csv', train_ratio=0.8, validation_ratio=0.1):\n",
    "    test_size = 1-train_ratio\n",
    "    validation_size = validation_ratio/test_size\n",
    "\n",
    "    # Load the CSV file using pandas\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert the pandas DataFrame into a Hugging Face Dataset\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "\n",
    "    if 0 < test_size < 1 :\n",
    "        # Split the dataset into train, validation, and test splits\n",
    "        dataset = dataset.train_test_split(test_size=test_size)  # Adjust the test_size as needed\n",
    "\n",
    "        # Assign the resulting splits to their respective variables\n",
    "        train_dataset = dataset['train']\n",
    "        test_dataset = dataset['test']\n",
    "\n",
    "        if 0 < validation_size < 1:\n",
    "            # Further split the train_dataset into train and validation splits\n",
    "            test_dataset = test_dataset.train_test_split(test_size=1-validation_size)  # Adjust the test_size as needed\n",
    "\n",
    "            # Assign the resulting splits to their respective variables\n",
    "            validation_dataset = test_dataset['train']\n",
    "            test_dataset = test_dataset['test']\n",
    "\n",
    "            # Create a DatasetDict to store the splits\n",
    "            dataset_dict = DatasetDict({'train': train_dataset, 'validation': validation_dataset, 'test': test_dataset})\n",
    "        elif validation_size >= 1:\n",
    "            print(f'Wrong validation ratio:{validation_size} should be < 1')\n",
    "            dataset_dict = DatasetDict({'train': train_dataset, 'validation': test_dataset})\n",
    "        else:\n",
    "            print(f'Wrong validation ratio:{validation_size} should be > 0 ')\n",
    "            dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "\n",
    "    else:\n",
    "        print(f'Wrong train ratio:{test_size} should be >0 1')\n",
    "        dataset_dict = DatasetDict({'train': dataset})\n",
    "        \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eec479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3680\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 460\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=0.8, validation_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "441eb2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong validation ratio:0.00 should be > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 920\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=0.8, validation_ratio=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb285e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e31d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong train ratio:0.00 should be > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=0, validation_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e2931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong validation ratio:4.00 should be < 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3680\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 920\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=0.8, validation_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca964f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3680\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 230\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 690\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_valid_test_from_file(train_ratio=0.8, validation_ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "\n",
    "#def train_milelens_model(pretrain_model: str = \"hfl/chinese-bert-wwm-ext\", use_wandb: bool = True):\n",
    "pretrain_model = \"hfl/chinese-bert-wwm-ext\"\n",
    "use_wandb = True\n",
    "if True:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        use_wandb:\n",
    "            Determine to use wandb to track training metrics\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # milelens_ds = LoadDatasets(\n",
    "    #     'ChnSentiCorp', 'fb_reply_230103', 'imdb', 'weibo_senti_100k',\n",
    "    #     'online_shopping_10_cats', 'waimai_10k', 'JD_pos', 'JD_neg', 'ntu_train_data_230428'\n",
    "    # )\n",
    "    #print(milelens_ds.data_infos)\n",
    "    #ds = milelens_ds.get_dataset_dict()\n",
    "    ds = dataset.train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted.csv')\n",
    "\n",
    "    id2label = dict(zip(label_dict.values(), label_dict.keys()))\n",
    "    label2id = label_dict\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "    modeler = AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "    tokenized_ds = ds.map(preprocess_function, batched=True)\n",
    "\n",
    "    # Data collator that will dynamically pad the inputs received\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Use wandb to track training metrics\n",
    "    report_args = []\n",
    "    if use_wandb:\n",
    "        wandb.init(project=\"milelens-ml-advertorial\")\n",
    "\n",
    "        report_args.append(\"wandb\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=3e-5,\n",
    "        per_device_train_batch_size=10,\n",
    "        per_device_eval_batch_size=50,\n",
    "        num_train_epochs=10,\n",
    "        logging_steps=10000,\n",
    "        save_steps=10000,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.05,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        output_dir=\"prebuilt_model/log\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=modeler,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d803cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79094f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def _is_control(char):\n",
    "    \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "    # These are technically control characters but we count them as whitespace\n",
    "    # characters.\n",
    "    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return False\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat.startswith(\"C\"):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e15a4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_whitespace(char):\n",
    "    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "    # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "    # as whitespace since they are generally considered as such.\n",
    "    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "        return True\n",
    "    cat = unicodedata.category(char)\n",
    "    if cat == \"Zs\":\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb545477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_text(text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "        cp = ord(char)\n",
    "        if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "            continue\n",
    "        if _is_whitespace(char):\n",
    "            output.append(\" \")\n",
    "        else:\n",
    "            output.append(char)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a30c774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'😮💨😮💨😮💨'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_clean_text(tokenized_advertorial[\"train\"][2292]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50bee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2dc51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/gitlab/advertorial-classifier\n",
      "Wrong validation ratio:1.00 should be < 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/jupyter/gitlab/advertorial-classifier/')\n",
    "print(os.getcwd())\n",
    "#sys.path.insert(0, os.getcwd())\n",
    "#os.chdir('../../advertorial-classifier/')\n",
    "#import sys\n",
    "#sys.path.insert(0, )\n",
    "\n",
    "# %%\n",
    "from advertorial import dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "#import wandb\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# %%\n",
    "# advertorial_dataset = dataset.train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted.csv')\n",
    "# train, validation, test = advertorial_dataset['train'], advertorial_dataset['validation'], advertorial_dataset['test'] \n",
    "# id2label = {0: \"no\", 1: \"yes\"}\n",
    "# label2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "# pretrain_model =\"hfl/chinese-bert-wwm-ext\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(pretrain_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     pretrain_model, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "\n",
    "\n",
    "advertorial_dataset = dataset.train_valid_test_from_file(csv_file_path= './data/milelens_advertorial_dataset_formatted_23634.csv', train_ratio=0.8, validation_ratio=0.2)\n",
    "train = advertorial_dataset['train']\n",
    "valid = advertorial_dataset['validation']\n",
    "id2label = {0: \"no\", 1: \"yes\"}\n",
    "label2id = {\"no\": 0, \"yes\": 1}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
